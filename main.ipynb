{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGARITHMIC_BANDS = [(1, 20), (21, 40), (41, 80), (81, 160), (161, 512)]\n",
    "\n",
    "def get_spectogram(\n",
    "    mp3_file, n_fft=2205, record_length: None | int = None, random_seed=42\n",
    "):\n",
    "    random.seed(random_seed)\n",
    "    # if record length exists, load the audio file with the duration, with random start point\n",
    "    if record_length is not None:\n",
    "        y, sr = librosa.load(\n",
    "            mp3_file,\n",
    "            duration=record_length,\n",
    "            offset=random.random() * (librosa.get_duration(filename=mp3_file) - record_length),\n",
    "        )\n",
    "    else:\n",
    "        y, sr = librosa.load(mp3_file)\n",
    "\n",
    "    # encrypt the audio file\n",
    "\n",
    "    fft_results = librosa.amplitude_to_db(librosa.core.stft(y, n_fft=n_fft))\n",
    "\n",
    "    return fft_results, sr\n",
    "\n",
    "\n",
    "def save_spectograms(\n",
    "    mp3_files: list, filepath: str, n_fft: int = 2205, record_length: None | int = None\n",
    "):\n",
    "    spectograms = {}\n",
    "    for filename, path in mp3_files.items():\n",
    "        fft_results, sr = get_spectogram(path, n_fft, record_length)\n",
    "\n",
    "        spectograms[os.path.splitext(filename)[0]] = fft_results\n",
    "\n",
    "    filepath = filepath + f\"{n_fft}_{len(mp3_files)}.npy\"\n",
    "    np.save(filepath, spectograms,)\n",
    "\n",
    "\n",
    "def create_constellation_map(\n",
    "    fft_results, frame_duration=0.1, sr=22050, hop_length=551, mean_coefficient=0.8\n",
    "):\n",
    "    # Define logarithmic bands\n",
    "    \n",
    "\n",
    "    frame_length = int(frame_duration * sr // hop_length)\n",
    "    times = librosa.times_like(fft_results)\n",
    "    selected_bins_over_time = []\n",
    "\n",
    "    # Step 2: Find the strongest bin for each band within 0.1-second intervals\n",
    "    for frame_start in range(0, len(times), frame_length):\n",
    "        frame_end = frame_start + frame_length\n",
    "        frame_bins = []\n",
    "        frame_bin_powers = []\n",
    "\n",
    "        for start_bin, end_bin in LOGARITHMIC_BANDS:\n",
    "            max_magnitude = -1\n",
    "            strongest_bin = None\n",
    "\n",
    "            for bin_num in range(start_bin, end_bin):\n",
    "                band_fft = np.abs(fft_results[bin_num, frame_start:frame_end])\n",
    "                max_magnitude_in_band = np.max(band_fft)\n",
    "\n",
    "                if max_magnitude_in_band > max_magnitude:\n",
    "                    max_magnitude = max_magnitude_in_band\n",
    "                    strongest_bin = bin_num\n",
    "\n",
    "            frame_bins.append(strongest_bin)\n",
    "            frame_bin_powers.append(max_magnitude)\n",
    "\n",
    "        threshold = mean_coefficient * np.mean(frame_bin_powers)\n",
    "        selected_bins = np.where(np.array(frame_bin_powers) > threshold)[0]\n",
    "        frame_bins = np.array(frame_bins)[selected_bins]\n",
    "\n",
    "        selected_bins_over_time.append(frame_bins)\n",
    "\n",
    "    constellation_map = []\n",
    "\n",
    "    for i, frame_bins in enumerate(selected_bins_over_time):\n",
    "        for bin in frame_bins:\n",
    "            constellation_map.append((times[i * frame_length], bin))\n",
    "\n",
    "    return constellation_map\n",
    "\n",
    "\n",
    "def save_constellation_maps(\n",
    "    spectograms: str,\n",
    "    filepath,\n",
    "    frame_duration=0.1,\n",
    "    sr=22050,\n",
    "    hop_length=551,\n",
    "    mean_coefficient=0.8,\n",
    "):\n",
    "    spectograms = np.load(spectograms, allow_pickle=True).item()\n",
    "    constellation_maps = {}\n",
    "    for song_id, fft_results in spectograms.items():\n",
    "        constellation_map = create_constellation_map(\n",
    "            fft_results, frame_duration, sr, hop_length, mean_coefficient\n",
    "        )\n",
    "        constellation_maps[song_id] = constellation_map\n",
    "\n",
    "    filepath = filepath + f\"{len(spectograms)}_{mean_coefficient}.npy\"\n",
    "    np.save(filepath, constellation_maps)\n",
    "\n",
    "\n",
    "def plot_constellation_map(\n",
    "    constellation_map, with_indexes=True, duration=None, offset=0\n",
    "):\n",
    "    _constellation_map = [\n",
    "        (time, freq) for time, freq in constellation_map if time >= offset\n",
    "    ]\n",
    "    if duration is not None:\n",
    "        _constellation_map = list(\n",
    "            filter(lambda x: x[0] < duration + offset, _constellation_map)\n",
    "        )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(\n",
    "        [time for time, _ in _constellation_map],\n",
    "        [bin for _, bin in _constellation_map],\n",
    "        marker=\"x\",\n",
    "        color=\"b\",\n",
    "    )\n",
    "\n",
    "    if with_indexes:\n",
    "        for i in range(len(_constellation_map)):\n",
    "            plt.annotate(str(i), _constellation_map[i])\n",
    "\n",
    "    plt.title(\"Selected Frequency Bins Over Time (First 1 Seconds)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency Bins\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def find_target_zone_for_anchor(\n",
    "    constellation_map, anchor_time, anchor_freq, anchor_index, target_zone_size=5\n",
    ") -> int | None:\n",
    "    step = int(np.ceil(target_zone_size / 2))\n",
    "    interval = 0\n",
    "    for i in range(anchor_index + 1, len(constellation_map)):\n",
    "        time, freq = constellation_map[i]\n",
    "        if time - anchor_time == 0:\n",
    "            interval += 1\n",
    "            continue\n",
    "        elif interval < step:\n",
    "            interval += 1\n",
    "            continue\n",
    "        else:\n",
    "            return i\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_address_value_couples(constellation_map, song_id: str, zone_size=5):\n",
    "    addresses_couples = []\n",
    "\n",
    "    for i, (anchor_time, anchor_freq) in enumerate(constellation_map):\n",
    "        target_zone_start = find_target_zone_for_anchor(\n",
    "            constellation_map, anchor_time, anchor_freq, i, zone_size\n",
    "        )\n",
    "        if target_zone_start is None:\n",
    "            break\n",
    "\n",
    "        target_zone_end = (\n",
    "            target_zone_start + zone_size\n",
    "            if target_zone_start + zone_size < len(constellation_map)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        if target_zone_end is None:\n",
    "            break\n",
    "\n",
    "        target_zone = constellation_map[target_zone_start:target_zone_end]\n",
    "\n",
    "        for time, freq in target_zone:\n",
    "            address_couple = [\n",
    "                anchor_freq,\n",
    "                freq,\n",
    "                time - anchor_time,\n",
    "                anchor_time,\n",
    "                float(song_id),\n",
    "            ]\n",
    "\n",
    "            addresses_couples.append(address_couple)\n",
    "\n",
    "    return np.array(addresses_couples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audios(path, num_audios=10):\n",
    "    audios = {}\n",
    "\n",
    "    folders = os.listdir(path)\n",
    "\n",
    "    loaded = 0\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(os.path.join(path, folder)):\n",
    "            continue\n",
    "        if loaded == num_audios:\n",
    "            break\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        audio_files = os.listdir(folder_path)\n",
    "        for audio_file in audio_files:\n",
    "            if not audio_file.endswith(\".mp3\"):\n",
    "                continue\n",
    "            if loaded == num_audios:\n",
    "                break\n",
    "\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            audios[os.path.splitext(audio_file)[0]] = audio_path\n",
    "            loaded += 1\n",
    "\n",
    "    return audios\n",
    "\n",
    "\n",
    "def create_address_couples(constellations_file: str):\n",
    "    constellations = np.load(constellations_file, allow_pickle=True).item()\n",
    "    addresses_couples = []\n",
    "\n",
    "    for song_id, constellation_map in constellations.items():\n",
    "        addresses_couples.append(\n",
    "            create_address_value_couples(constellation_map, song_id)\n",
    "        )\n",
    "\n",
    "    return np.concatenate(addresses_couples)\n",
    "\n",
    "\n",
    "def create_address_couples_from_spectograms(spectograms_file: str):\n",
    "    spectograms = np.load(spectograms_file, allow_pickle=True).item()\n",
    "    addresses_couples = []\n",
    "\n",
    "    for song_id, spectogram in spectograms.items():\n",
    "        constellation_map = create_constellation_map(spectogram)\n",
    "\n",
    "        addresses_couples.append(\n",
    "            create_address_value_couples(constellation_map, song_id)\n",
    "        )\n",
    "\n",
    "    return np.concatenate(addresses_couples)\n",
    "\n",
    "\n",
    "def create_address_couples_from_audios(audios: dict):\n",
    "    addresses_couples = []\n",
    "\n",
    "    for song_id, audio_path in audios.items():\n",
    "        fft_results, sr = get_spectogram(audio_path)\n",
    "        constellation_map = create_constellation_map(fft_results)\n",
    "\n",
    "        addresses_couples.append(\n",
    "            create_address_value_couples(constellation_map, song_id)\n",
    "        )\n",
    "\n",
    "    return np.concatenate(addresses_couples)\n",
    "\n",
    "\n",
    "def search_address(db: np.array, query: np.array):\n",
    "    matched_indicies = []\n",
    "\n",
    "    unique_query, counts = np.unique(query, axis=0, return_counts=True)\n",
    "\n",
    "    count = 1\n",
    "    # select the rows that have count == count\n",
    "    selected_query = unique_query[counts == count]\n",
    "    # np.sum(element == x) > 0\n",
    "    while len(selected_query) != 0:\n",
    "        matches = np.isin(db[:, :3], selected_query).all(axis=1)\n",
    "        matched_indicies.append(np.where(matches)[0])\n",
    "\n",
    "        count += 1\n",
    "        selected_query = unique_query[counts == count]\n",
    "\n",
    "    matched_indices = np.concatenate(matched_indicies)\n",
    "\n",
    "    return db[matched_indices]\n",
    "\n",
    "\n",
    "def process_matches(matches: np.array):\n",
    "    # Count the matches by song ID, count anchor times that the ones are larger than 5,\n",
    "    # Create a dictionary with the song id as the key, and the value is also a dictionary which has address_matches and target_zone_matches as the keys, and the values are the counts.\n",
    "\n",
    "    # Initialize the list of tuples to store the matches for each song id\n",
    "    song_matches = []\n",
    "\n",
    "    # Find unique song ids\n",
    "    song_ids = np.unique(matches[:, 4])\n",
    "\n",
    "    # Loop over each song id\n",
    "    for song_id in song_ids:\n",
    "        # Filter the list of matches to get the matches for the current song id\n",
    "        song_matches_filtered = matches[matches[:, 4] == song_id]\n",
    "\n",
    "        # Find the unique 4th numbers for the current song id\n",
    "        _, counts_4th_numbers = np.unique(\n",
    "            song_matches_filtered[:, [0, 3]], axis=0, return_counts=True\n",
    "        )\n",
    "\n",
    "        # Calculate the target zone matches for each unique 4th number\n",
    "        target_zone_matches = np.sum(counts_4th_numbers // 5)\n",
    "\n",
    "        song_matches.append(\n",
    "            (song_id, np.sum(target_zone_matches), len(song_matches_filtered))\n",
    "        )\n",
    "\n",
    "    # sort the song matches by the number of target zone matches then the number of address matches in descending order\n",
    "    song_matches = sorted(song_matches, key=lambda x: (x[1], x[2]), reverse=True)\n",
    "\n",
    "    return song_matches\n",
    "\n",
    "\n",
    "def print_results(song_matches: list, num_results=3, song_id: float = None):\n",
    "    # print green if the first result is the target song, print yellow if one of the first three guesses is correct, otherwise print red\n",
    "    if song_matches[0][0] == song_id:\n",
    "        print(\"\\033[92m\" + \"The target song is found correct!\" + \"\\033[0m\")\n",
    "    elif song_matches[1][0] == song_id or song_matches[2][0] == song_id:\n",
    "        print(\n",
    "            \"\\033[93m\"\n",
    "            + \"The target song is found in the first three guesses\"\n",
    "            + \"\\033[0m\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\033[91m\" + \"The target song is not found correct\" + \"\\033[0m\")\n",
    "    i = 0\n",
    "    for song_id, target_zone_matches, address_matches in song_matches:\n",
    "        print(\n",
    "            f\"Song ID: {int(song_id)}, Target Zone Matches: {target_zone_matches}, Address Matches: {address_matches}\"\n",
    "        )\n",
    "        i += 1\n",
    "        if i == num_results:\n",
    "            break\n",
    "\n",
    "\n",
    "def search_song(\n",
    "    db: np.array,\n",
    "    target_audio_path: str,\n",
    "    target_audio_record_seconds: int = 3,\n",
    "    report: bool = True,\n",
    "    n_fft=2205,\n",
    "    mean_coefficient=0.8,\n",
    "    zone_size=5,\n",
    "):\n",
    "    fft_results, sr = get_spectogram(\n",
    "        target_audio_path, record_length=target_audio_record_seconds, n_fft=n_fft\n",
    "    )\n",
    "    constellation_map = create_constellation_map(fft_results, mean_coefficient=mean_coefficient, hop_length=n_fft // 4)\n",
    "    song_id = os.path.splitext(os.path.basename(target_audio_path))[0]\n",
    "    addresses_couples = create_address_value_couples(\n",
    "        constellation_map, song_id, zone_size=zone_size\n",
    "    )\n",
    "    # select the first 3 columns as the addresses\n",
    "    addresses = addresses_couples[:, :3]\n",
    "    results = search_address(db, addresses)\n",
    "    processed_results = process_matches(results)\n",
    "    if report:\n",
    "        print_results(processed_results, song_id=float(song_id))\n",
    "    \n",
    "    if len(processed_results) == 0:\n",
    "        return constellation_map, results, False, False\n",
    "    found = processed_results[0][0] == float(song_id)\n",
    "    \n",
    "    found_in_first_three = float(song_id) in np.array(processed_results[:3])[:, 0] \n",
    "\n",
    "    return constellation_map, results, found, found_in_first_three\n",
    "\n",
    "\n",
    "def run_experiment(number_of_audios, n_fft, mean_coefficient, zone_size, recording_length):\n",
    "    # Load the audios\n",
    "    audios = load_audios(\"data/fma_small/\", num_audios=number_of_audios)\n",
    "\n",
    "    # Save the spectograms if not exists\n",
    "    if not os.path.exists(f\"spectograms/{n_fft}_{len(audios)}.npy\"):\n",
    "        save_spectograms(audios, \"cache/spectograms/\", n_fft, recording_length)\n",
    "        \n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Save the constellation maps if not exists\n",
    "    if not os.path.exists(f\"constellation_maps/{len(audios)}_{mean_coefficient}.npy\"):\n",
    "        save_constellation_maps(\n",
    "            f\"cache/spectograms/{n_fft}_{number_of_audios}.npy\",\n",
    "            \"cache/constellation_maps/\",\n",
    "            mean_coefficient=mean_coefficient,\n",
    "            hop_length=n_fft // 4,\n",
    "        )\n",
    "\n",
    "    # Create the address couples\n",
    "    addresses_couples = create_address_couples(f'cache/constellation_maps/{number_of_audios}_{mean_coefficient}.npy')\n",
    "\n",
    "    # Search all the audios in the database one by one\n",
    "    found = 0\n",
    "    found_in_first_three = 0\n",
    "\n",
    "    for song_id, audio_path in audios.items():\n",
    "        _, _, _found, _found_in_first_three = search_song(\n",
    "            addresses_couples,\n",
    "            audio_path,\n",
    "            target_audio_record_seconds=recording_length,\n",
    "            report=False,\n",
    "            n_fft=n_fft,\n",
    "            mean_coefficient=mean_coefficient,\n",
    "            zone_size=zone_size,\n",
    "        )\n",
    "        if _found:\n",
    "            found += 1\n",
    "        if _found_in_first_three:\n",
    "            found_in_first_three += 1\n",
    "\n",
    "    # Append configurations and results to the csv file\n",
    "\n",
    "    found = found / number_of_audios * 100\n",
    "    found_in_first_three = found_in_first_three / number_of_audios * 100\n",
    "\n",
    "    columns = [\n",
    "        \"Number of Audios\",\n",
    "        \"n_fft\",\n",
    "        \"Mean Coefficient\",\n",
    "        \"Zone Size\",\n",
    "        \"Recording Length\",\n",
    "        \"Found\",\n",
    "        \"Found in First Three\",\n",
    "    ]\n",
    "\n",
    "    data = [\n",
    "        [\n",
    "            number_of_audios,\n",
    "            n_fft,\n",
    "            mean_coefficient,\n",
    "            zone_size,\n",
    "            recording_length,\n",
    "            found,\n",
    "            found_in_first_three,\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    reports = pd.read_csv(\"experiment_results.csv\")\n",
    "    reports = pd.concat([reports, df], ignore_index=True)\n",
    "    reports.to_csv(\"experiment_results.csv\", index=False)\n",
    "\n",
    "    print(f\"Found: {found}%\")\n",
    "    print(f\"Found in first three: {found_in_first_three}%\")\n",
    "\n",
    "    return found, found_in_first_three\n",
    "\n",
    "\n",
    "def grid_search():\n",
    "    candidate_audio_numbers = [10, 50, 100]\n",
    "    candidate_n_fft = [2205, 2048]\n",
    "    candidate_mean_coefficient = [0.8, 0.9, 1]\n",
    "    candidate_zone_size = [5, 10, 20]\n",
    "    candidate_recording_length = [5, 10, 20]\n",
    "    # Grid search\n",
    "    \n",
    "    searched_configs = pd.read_csv(\"experiment_results.csv\")\n",
    "    \n",
    "    for number_of_audios in candidate_audio_numbers:\n",
    "        for n_fft in candidate_n_fft:\n",
    "            for mean_coefficient in candidate_mean_coefficient:\n",
    "                for zone_size in candidate_zone_size:\n",
    "                    for recording_length in candidate_recording_length:\n",
    "                        config_row = {\n",
    "                            \"Number of Audios\": [number_of_audios],\n",
    "                            \"n_fft\": [n_fft],\n",
    "                            \"Mean Coefficient\": [mean_coefficient],\n",
    "                            \"Zone Size\": [zone_size],\n",
    "                            \"Recording Length\": [recording_length],\n",
    "                        }\n",
    "                        \n",
    "                        if not searched_configs.iloc[:, : 5].isin(config_row).all(axis=1).any():\n",
    "                            run_experiment(\n",
    "                                number_of_audios,\n",
    "                                n_fft,\n",
    "                                mean_coefficient,\n",
    "                                zone_size,\n",
    "                                recording_length,\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\"Skipped\")\n",
    "                            print(config_row)\n",
    "                            print(\"-\" * 20)\n",
    "                            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHUNKING FOR OPTIMIZATION\n",
    "\n",
    "def chunkify(target_array):\n",
    "    chunked_array = []\n",
    "    \n",
    "    for band in LOGARITHMIC_BANDS:\n",
    "        band_array = target_array[(target_array[:, 0] >= band[0]) & (target_array[:, 0] < band[1])]\n",
    "        chunked_array.append(band_array)\n",
    "    return chunked_array\n",
    "\n",
    "def search_chunked_address(db: np.array, _query: np.array):\n",
    "    results = []\n",
    "    \n",
    "    for i, query in enumerate(_query):\n",
    "        matched_indicies = []\n",
    "        \n",
    "\n",
    "        unique_query, counts = np.unique(query, axis=0, return_counts=True)\n",
    "\n",
    "        count = 1\n",
    "        # select the rows that have count == count\n",
    "        selected_query = unique_query[counts == count]\n",
    "        # np.sum(element == x) > 0\n",
    "        while len(selected_query) != 0:\n",
    "            matches = np.isin(db[i][:, :3], selected_query).all(axis=1)\n",
    "            matched_indicies.append(np.where(matches)[0])\n",
    "\n",
    "            count += 1\n",
    "            selected_query = unique_query[counts == count]\n",
    "\n",
    "        if len(matched_indicies) == 0:\n",
    "            continue\n",
    "        matched_indices = np.concatenate(matched_indicies)\n",
    "        results.append(db[i][matched_indices])\n",
    "\n",
    "    return np.concatenate(results)\n",
    "\n",
    "def chunked_search_song(\n",
    "    db: np.array,\n",
    "    target_audio_path: str,\n",
    "    target_audio_record_seconds: int = 3,\n",
    "    report: bool = True,\n",
    "    n_fft=2205,\n",
    "    mean_coefficient=0.8,\n",
    "    zone_size=5,\n",
    "):\n",
    "    fft_results, sr = get_spectogram(\n",
    "        target_audio_path, record_length=target_audio_record_seconds, n_fft=n_fft\n",
    "    )\n",
    "    constellation_map = create_constellation_map(fft_results, mean_coefficient=mean_coefficient, hop_length=n_fft // 4)\n",
    "    song_id = os.path.splitext(os.path.basename(target_audio_path))[0]\n",
    "    addresses_couples = create_address_value_couples(\n",
    "        constellation_map, song_id, zone_size=zone_size\n",
    "    )\n",
    "    addresses_couples = addresses_couples[:, :3]\n",
    "    addresses = chunkify(addresses_couples)\n",
    "    results = search_chunked_address(db, addresses)\n",
    "    processed_results = process_matches(results)\n",
    "    if report:\n",
    "        print_results(processed_results, song_id=float(song_id))\n",
    "        \n",
    "    if len(processed_results) == 0:\n",
    "        return constellation_map, results, False, False\n",
    "    \n",
    "    found = processed_results[0][0] == float(song_id)\n",
    "    \n",
    "    found_in_first_three = float(song_id) in np.array(processed_results[:3])[:, 0]\n",
    "    \n",
    "    return constellation_map, results, found, found_in_first_three\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_AUDIOS = 100\n",
    "MEAN_COEFFICIENT = 0.8\n",
    "N_FFT = 2205\n",
    "ZONE_SIZE = 5\n",
    "RECORDING_LENGTH = 5\n",
    "\n",
    "\n",
    "audios = load_audios(\"data/fma_small/\", num_audios=NUMBER_OF_AUDIOS)\n",
    "\n",
    "# Save the spectograms if not exists\n",
    "if not os.path.exists(f\"spectograms/{N_FFT}_{len(audios)}.npy\"):\n",
    "    save_spectograms(audios, \"cache/spectograms/\", N_FFT, RECORDING_LENGTH)\n",
    "    \n",
    "time.sleep(0.5)\n",
    "\n",
    "# Save the constellation maps if not exists\n",
    "if not os.path.exists(f\"constellation_maps/{len(audios)}_{MEAN_COEFFICIENT}.npy\"):\n",
    "    save_constellation_maps(\n",
    "        f\"cache/spectograms/{N_FFT}_{NUMBER_OF_AUDIOS}.npy\",\n",
    "        \"cache/constellation_maps/\",\n",
    "        mean_coefficient=MEAN_COEFFICIENT,\n",
    "        hop_length=N_FFT // 4,\n",
    "    )\n",
    "\n",
    "# Create the address couples\n",
    "addresses_couples = create_address_couples(f'cache/constellation_maps/{NUMBER_OF_AUDIOS}_{MEAN_COEFFICIENT}.npy')\n",
    "# addresses_couples = chunkify(addresses_couples)\n",
    "\n",
    "# Search all the audios in the database one by one\n",
    "found = 0\n",
    "found_in_first_three = 0\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for song_id, audio_path in audios.items():\n",
    "    print(f\"Searching {song_id}\")\n",
    "    t1 = time.time()\n",
    "    _, _, _found, _found_in_first_three = search_song(\n",
    "        addresses_couples,\n",
    "        audio_path,\n",
    "        target_audio_record_seconds=RECORDING_LENGTH,\n",
    "        n_fft=N_FFT,\n",
    "        mean_coefficient=MEAN_COEFFICIENT,\n",
    "        zone_size=ZONE_SIZE,\n",
    "        report=False\n",
    "    )\n",
    "    total_time += time.time() - t1\n",
    "    if _found:\n",
    "        found += 1\n",
    "    if _found_in_first_three:\n",
    "        found_in_first_three += 1\n",
    "    \n",
    "# not chunked db average search time = 0.2715\n",
    "# chunked db average search time = 0.2391\n",
    "\n",
    "print(\n",
    "f\"Accuracy(definite): {found / len(audios) * 100}%, Accuracy(relative): {found_in_first_three / len(audios) * 100}%, Average Search Time: {total_time / len(audios)}s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import concrete as fhe\n",
    "\n",
    "\n",
    "@fhe.circuit(\n",
    "    {\"db\": \"unencrypted\", \"f1\": \"unencrypted\", \"f2\": \"encrypted\", \"time\": \"unencrypted\"}\n",
    ")\n",
    "def func(db: np.array, f1: np.uint16, f2: fhe.uint16, time: np.float32):\n",
    "    selected_query = np.stack((f1, f2, time), axis=1)\n",
    "\n",
    "    matched_indices = []\n",
    "    matches = np.isin(db[:, :3], selected_query).all(axis=1)\n",
    "    matched_indices.append(np.where(matches)[0].tolist())\n",
    "\n",
    "    return db[matched_indices]\n",
    "\n",
    "\n",
    "class KeyValueDatabase:\n",
    "    _state: list[np.ndarray]\n",
    "\n",
    "    _query_circuit: any\n",
    "\n",
    "    def __init__(self):\n",
    "        self._state = []\n",
    "\n",
    "        configuration = fhe.Configuration(\n",
    "            enable_unsafe_features=True,\n",
    "            use_insecure_key_cache=True,\n",
    "            insecure_key_cache_location=\".keys\",\n",
    "        )\n",
    "\n",
    "        query_compiler = fhe.Compiler(func)\n",
    "\n",
    "        print(\"Compiling query circuit...\")\n",
    "        start = time.time()\n",
    "        self._query_circuit = query_compiler.compile(configuration)\n",
    "        end = time.time()\n",
    "        print(f\"(took {end - start:.3f} seconds)\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(\"Generating query keys...\")\n",
    "        start = time.time()\n",
    "        self._query_circuit.keygen()\n",
    "        end = time.time()\n",
    "        print(f\"(took {end - start:.3f} seconds)\")\n",
    "\n",
    "    def query(self, key):\n",
    "        print()\n",
    "        print(f\"Querying...\")\n",
    "        start = time.time()\n",
    "\n",
    "        accumulation = np.zeros(1 + NUMBER_OF_VALUE_CHUNKS, dtype=np.uint64)\n",
    "        for entry in self._state:\n",
    "            accumulation += self._query_circuit.encrypt_run_decrypt(key, *entry)\n",
    "\n",
    "        match_count = accumulation[0]\n",
    "        if match_count > 1:\n",
    "            raise RuntimeError(\"Key inserted multiple times\")\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"(took {end - start:.3f} seconds)\")\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Audios</th>\n",
       "      <th>n_fft</th>\n",
       "      <th>Mean Coefficient</th>\n",
       "      <th>Zone Size</th>\n",
       "      <th>Recording Length</th>\n",
       "      <th>Found</th>\n",
       "      <th>Found in First Three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>100</td>\n",
       "      <td>2205</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>100</td>\n",
       "      <td>2205</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>100</td>\n",
       "      <td>2205</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>100</td>\n",
       "      <td>2205</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>100</td>\n",
       "      <td>2205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>100</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>100</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>100</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>100</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>100</td>\n",
       "      <td>2048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>50</td>\n",
       "      <td>2205</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>50</td>\n",
       "      <td>2205</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>50</td>\n",
       "      <td>2205</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>50</td>\n",
       "      <td>2205</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>50</td>\n",
       "      <td>2205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>50</td>\n",
       "      <td>2205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>50</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>50</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>50</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>50</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of Audios  n_fft  Mean Coefficient  Zone Size  Recording Length  \\\n",
       "108               100   2205               0.8          5                 5   \n",
       "111               100   2205               0.8         10                 5   \n",
       "117               100   2205               0.9          5                 5   \n",
       "120               100   2205               0.9         10                 5   \n",
       "126               100   2205               1.0          5                 5   \n",
       "135               100   2048               0.8          5                 5   \n",
       "138               100   2048               0.8         10                 5   \n",
       "144               100   2048               0.9          5                 5   \n",
       "147               100   2048               0.9         10                 5   \n",
       "153               100   2048               1.0          5                 5   \n",
       "54                 50   2205               0.8          5                 5   \n",
       "57                 50   2205               0.8         10                 5   \n",
       "63                 50   2205               0.9          5                 5   \n",
       "66                 50   2205               0.9         10                 5   \n",
       "72                 50   2205               1.0          5                 5   \n",
       "75                 50   2205               1.0         10                 5   \n",
       "81                 50   2048               0.8          5                 5   \n",
       "84                 50   2048               0.8         10                 5   \n",
       "90                 50   2048               0.9          5                 5   \n",
       "93                 50   2048               0.9         10                 5   \n",
       "\n",
       "     Found  Found in First Three  \n",
       "108  100.0                 100.0  \n",
       "111  100.0                 100.0  \n",
       "117  100.0                 100.0  \n",
       "120  100.0                 100.0  \n",
       "126  100.0                 100.0  \n",
       "135  100.0                 100.0  \n",
       "138  100.0                 100.0  \n",
       "144  100.0                 100.0  \n",
       "147  100.0                 100.0  \n",
       "153  100.0                 100.0  \n",
       "54   100.0                 100.0  \n",
       "57   100.0                 100.0  \n",
       "63   100.0                 100.0  \n",
       "66   100.0                 100.0  \n",
       "72   100.0                 100.0  \n",
       "75   100.0                 100.0  \n",
       "81   100.0                 100.0  \n",
       "84   100.0                 100.0  \n",
       "90   100.0                 100.0  \n",
       "93   100.0                 100.0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"experiment_results.csv\")\n",
    "df = df.sort_values(by=[\"Found\", \"Found in First Three\", \"Number of Audios\"], ascending=False)[df[\"Recording Length\"] == 5]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
