{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spectogram Functions ###\n",
    "\n",
    "\n",
    "def get_spectogram(\n",
    "    mp3_file, n_fft=2205, record_length: None | int = None, random_seed=42\n",
    "):\n",
    "    random.seed(random_seed)\n",
    "    # if record length exists, load the audio file with the duration, with random start point\n",
    "    if record_length is not None:\n",
    "        y, sr = librosa.load(\n",
    "            mp3_file,\n",
    "            duration=record_length,\n",
    "            offset=random.random()\n",
    "            * (librosa.get_duration(filename=mp3_file) - record_length),\n",
    "        )\n",
    "    else:\n",
    "        y, sr = librosa.load(mp3_file)\n",
    "\n",
    "    # encrypt the audio file\n",
    "\n",
    "    fft_results = librosa.amplitude_to_db(librosa.core.stft(y, n_fft=n_fft))\n",
    "\n",
    "    return fft_results, sr\n",
    "\n",
    "\n",
    "def save_spectograms(\n",
    "    mp3_files: list, filepath: str, n_fft: int = 2205, record_length: None | int = None\n",
    "):\n",
    "    spectograms = {}\n",
    "    for filename, path in mp3_files.items():\n",
    "        fft_results, sr = get_spectogram(path, n_fft, record_length)\n",
    "\n",
    "        spectograms[os.path.splitext(filename)[0]] = fft_results\n",
    "\n",
    "    filepath = filepath + f\"{n_fft}_{len(mp3_files)}.npy\"\n",
    "    np.save(\n",
    "        filepath,\n",
    "        spectograms,\n",
    "    )\n",
    "\n",
    "\n",
    "fft_results, sr = get_spectogram(\"data/fma_small/000/000002.mp3\", record_length=10)\n",
    "\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(fft_results, sr=sr, x_axis=\"time\", y_axis=\"hz\")\n",
    "# plt.colorbar()\n",
    "# plt.title(\"Spectogram\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constellation Map Functions ###\n",
    "\n",
    "LOGARITHMIC_BANDS = [(1, 20), (21, 40), (41, 80), (81, 160), (161, 512)]\n",
    "\n",
    "\n",
    "def create_constellation_map(\n",
    "    fft_results, frame_duration=0.1, sr=22050, hop_length=551, mean_coefficient=0.8\n",
    "):\n",
    "    frame_length = int(frame_duration * sr // hop_length)\n",
    "    times = librosa.times_like(fft_results)\n",
    "    selected_bins_over_time = []\n",
    "\n",
    "    for frame_start in range(0, len(times), frame_length):\n",
    "        frame_end = frame_start + frame_length\n",
    "        frame_bins = []\n",
    "        frame_bin_powers = []\n",
    "\n",
    "        for start_bin, end_bin in LOGARITHMIC_BANDS:\n",
    "            max_magnitude = -1\n",
    "            strongest_bin = None\n",
    "\n",
    "            for bin_num in range(start_bin, end_bin):\n",
    "                band_fft = np.abs(fft_results[bin_num, frame_start:frame_end])\n",
    "                max_magnitude_in_band = np.max(band_fft)\n",
    "\n",
    "                if max_magnitude_in_band > max_magnitude:\n",
    "                    max_magnitude = max_magnitude_in_band\n",
    "                    strongest_bin = bin_num\n",
    "\n",
    "            frame_bins.append(strongest_bin)\n",
    "            frame_bin_powers.append(max_magnitude)\n",
    "\n",
    "        threshold = mean_coefficient * np.mean(frame_bin_powers)\n",
    "        selected_bins = np.where(np.array(frame_bin_powers) > threshold)[0]\n",
    "        frame_bins = np.array(frame_bins)[selected_bins]\n",
    "\n",
    "        selected_bins_over_time.append(frame_bins)\n",
    "\n",
    "    constellation_map = []\n",
    "\n",
    "    for i, frame_bins in enumerate(selected_bins_over_time):\n",
    "        for bin in frame_bins:\n",
    "            constellation_map.append((times[i * frame_length], bin))\n",
    "\n",
    "    return constellation_map\n",
    "\n",
    "\n",
    "def save_constellation_maps(\n",
    "    spectograms: str,\n",
    "    filepath,\n",
    "    frame_duration=0.1,\n",
    "    sr=22050,\n",
    "    hop_length=551,\n",
    "    mean_coefficient=0.8,\n",
    "):\n",
    "    spectograms = np.load(spectograms, allow_pickle=True).item()\n",
    "    constellation_maps = {}\n",
    "    for song_id, fft_results in spectograms.items():\n",
    "        constellation_map = create_constellation_map(\n",
    "            fft_results, frame_duration, sr, hop_length, mean_coefficient\n",
    "        )\n",
    "        constellation_maps[song_id] = constellation_map\n",
    "\n",
    "    filepath = filepath + f\"{len(spectograms)}_{mean_coefficient}.npy\"\n",
    "    np.save(filepath, constellation_maps)\n",
    "\n",
    "\n",
    "def plot_constellation_map(\n",
    "    constellation_map, with_indexes=True, duration=None, offset=0\n",
    "):\n",
    "    _constellation_map = [\n",
    "        (time, freq) for time, freq in constellation_map if time >= offset\n",
    "    ]\n",
    "    if duration is not None:\n",
    "        _constellation_map = list(\n",
    "            filter(lambda x: x[0] < duration + offset, _constellation_map)\n",
    "        )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(\n",
    "        [time for time, _ in _constellation_map],\n",
    "        [bin for _, bin in _constellation_map],\n",
    "        marker=\"x\",\n",
    "        color=\"b\",\n",
    "    )\n",
    "\n",
    "    if with_indexes:\n",
    "        for i in range(len(_constellation_map)):\n",
    "            plt.annotate(str(i), _constellation_map[i])\n",
    "\n",
    "    plt.title(\"Selected Frequency Bins Over Time (First 1 Seconds)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency Bins\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "constellation_map = create_constellation_map(\n",
    "    fft_results, frame_duration=0.1, sr=sr, hop_length=551, mean_coefficient=0.8\n",
    ")\n",
    "# plot_constellation_map(constellation_map, with_indexes=False, duration=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Address Value Couple Functions ###\n",
    "\n",
    "\n",
    "def find_target_zone_for_anchor(\n",
    "    constellation_map, anchor_time, anchor_freq, anchor_index, target_zone_size=5\n",
    ") -> int | None:\n",
    "    step = int(np.ceil(target_zone_size / 2))\n",
    "    interval = 0\n",
    "    for i in range(anchor_index + 1, len(constellation_map)):\n",
    "        time, freq = constellation_map[i]\n",
    "        if time - anchor_time == 0:\n",
    "            interval += 1\n",
    "            continue\n",
    "        elif interval < step:\n",
    "            interval += 1\n",
    "            continue\n",
    "        else:\n",
    "            return i\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_address_value_couples(constellation_map, song_id: str, zone_size=5):\n",
    "    addresses_couples = []\n",
    "\n",
    "    for i, (anchor_time, anchor_freq) in enumerate(constellation_map):\n",
    "        target_zone_start = find_target_zone_for_anchor(\n",
    "            constellation_map, anchor_time, anchor_freq, i, zone_size\n",
    "        )\n",
    "        if target_zone_start is None:\n",
    "            break\n",
    "\n",
    "        target_zone_end = (\n",
    "            target_zone_start + zone_size\n",
    "            if target_zone_start + zone_size < len(constellation_map)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        if target_zone_end is None:\n",
    "            break\n",
    "\n",
    "        target_zone = constellation_map[target_zone_start:target_zone_end]\n",
    "\n",
    "        for time, freq in target_zone:\n",
    "            address_couple = [\n",
    "                anchor_freq,\n",
    "                freq,\n",
    "                time - anchor_time,\n",
    "                anchor_time,\n",
    "                float(song_id),\n",
    "            ]\n",
    "\n",
    "            addresses_couples.append(address_couple)\n",
    "\n",
    "    return np.array(addresses_couples)\n",
    "\n",
    "\n",
    "def create_address_couples(constellations_file: str):\n",
    "    constellations = np.load(constellations_file, allow_pickle=True).item()\n",
    "    addresses_couples = []\n",
    "\n",
    "    for song_id, constellation_map in constellations.items():\n",
    "        addresses_couples.append(\n",
    "            create_address_value_couples(constellation_map, song_id)\n",
    "        )\n",
    "\n",
    "    return np.concatenate(addresses_couples)\n",
    "\n",
    "\n",
    "def create_address_couples_from_spectograms(spectograms_file: str):\n",
    "    spectograms = np.load(spectograms_file, allow_pickle=True).item()\n",
    "    addresses_couples = []\n",
    "\n",
    "    for song_id, spectogram in spectograms.items():\n",
    "        constellation_map = create_constellation_map(spectogram)\n",
    "\n",
    "        addresses_couples.append(\n",
    "            create_address_value_couples(constellation_map, song_id)\n",
    "        )\n",
    "\n",
    "    return np.concatenate(addresses_couples)\n",
    "\n",
    "\n",
    "def create_address_couples_from_audios(audios: dict):\n",
    "    addresses_couples = []\n",
    "\n",
    "    for song_id, audio_path in audios.items():\n",
    "        fft_results, sr = get_spectogram(audio_path)\n",
    "        constellation_map = create_constellation_map(fft_results)\n",
    "\n",
    "        addresses_couples.append(\n",
    "            create_address_value_couples(constellation_map, song_id)\n",
    "        )\n",
    "\n",
    "    return np.concatenate(addresses_couples)\n",
    "\n",
    "\n",
    "address_couples = create_address_couples_from_audios(\n",
    "    {\"000002\": \"data/fma_small/000/000002.mp3\"}\n",
    ")\n",
    "print(\"Address couples shape:\")\n",
    "print(address_couples.shape)\n",
    "print(\"First 5 address couples:\")\n",
    "print(address_couples[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility Functions ###\n",
    "\n",
    "\n",
    "def load_audios(path, num_audios=10):\n",
    "    audios = {}\n",
    "\n",
    "    folders = os.listdir(path)\n",
    "\n",
    "    loaded = 0\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(os.path.join(path, folder)):\n",
    "            continue\n",
    "        if loaded == num_audios:\n",
    "            break\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        audio_files = os.listdir(folder_path)\n",
    "        for audio_file in audio_files:\n",
    "            if not audio_file.endswith(\".mp3\"):\n",
    "                continue\n",
    "            if loaded == num_audios:\n",
    "                break\n",
    "\n",
    "            audio_path = os.path.join(folder_path, audio_file)\n",
    "            audios[os.path.splitext(audio_file)[0]] = audio_path\n",
    "            loaded += 1\n",
    "\n",
    "    return audios\n",
    "\n",
    "\n",
    "audios = load_audios(\"data/fma_small\", num_audios=10)\n",
    "print(\"Loaded audios:\")\n",
    "pprint(audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_address(db: np.array, query: np.array):\n",
    "    matched_indicies = []\n",
    "\n",
    "    unique_query, counts = np.unique(query, axis=0, return_counts=True)\n",
    "\n",
    "    count = 1\n",
    "    selected_query = unique_query[counts == count]\n",
    "\n",
    "    while len(selected_query) != 0:\n",
    "        matches = np.isin(db[:, :3], selected_query).all(axis=1)\n",
    "        matched_indicies.append(np.where(matches)[0])\n",
    "\n",
    "        count += 1\n",
    "        selected_query = unique_query[counts == count]\n",
    "\n",
    "    matched_indices = np.concatenate(matched_indicies)\n",
    "\n",
    "    return db[matched_indices]\n",
    "\n",
    "\n",
    "def process_matches(matches: np.array):\n",
    "    # Count the matches by song ID, count anchor times that the ones are larger than 5,\n",
    "    # Create a dictionary with the song id as the key, and the value is also a dictionary which has address_matches and target_zone_matches as the keys, and the values are the counts.\n",
    "\n",
    "    # Initialize the list of tuples to store the matches for each song id\n",
    "    song_matches = []\n",
    "\n",
    "    # Find unique song ids\n",
    "    song_ids = np.unique(matches[:, 4])\n",
    "\n",
    "    # Loop over each song id\n",
    "    for song_id in song_ids:\n",
    "        # Filter the list of matches to get the matches for the current song id\n",
    "        song_matches_filtered = matches[matches[:, 4] == song_id]\n",
    "\n",
    "        # Find the unique 4th numbers for the current song id\n",
    "        _, counts_4th_numbers = np.unique(\n",
    "            song_matches_filtered[:, [0, 3]], axis=0, return_counts=True\n",
    "        )\n",
    "\n",
    "        # Calculate the target zone matches for each unique 4th number\n",
    "        target_zone_matches = np.sum(counts_4th_numbers // 5)\n",
    "\n",
    "        song_matches.append(\n",
    "            (song_id, np.sum(target_zone_matches), len(song_matches_filtered))\n",
    "        )\n",
    "\n",
    "    # sort the song matches by the number of target zone matches then the number of address matches in descending order\n",
    "    song_matches = sorted(song_matches, key=lambda x: (x[1], x[2]), reverse=True)\n",
    "\n",
    "    return song_matches\n",
    "\n",
    "\n",
    "def print_results(song_matches: list, num_results=3, song_id: float = None):\n",
    "    # print green if the first result is the target song, print yellow if one of the first three guesses is correct, otherwise print red\n",
    "    if song_matches[0][0] == song_id:\n",
    "        print(\"\\033[92m\" + \"The target song is found correct!\" + \"\\033[0m\")\n",
    "    elif song_matches[1][0] == song_id or song_matches[2][0] == song_id:\n",
    "        print(\n",
    "            \"\\033[93m\"\n",
    "            + \"The target song is found in the first three guesses\"\n",
    "            + \"\\033[0m\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\033[91m\" + \"The target song is not found correct\" + \"\\033[0m\")\n",
    "    i = 0\n",
    "    for song_id, target_zone_matches, address_matches in song_matches:\n",
    "        print(\n",
    "            f\"Song ID: {int(song_id)}, Target Zone Matches: {target_zone_matches}, Address Matches: {address_matches}\"\n",
    "        )\n",
    "        i += 1\n",
    "        if i == num_results:\n",
    "            break\n",
    "\n",
    "\n",
    "def search_song(\n",
    "    db: np.array,\n",
    "    target_audio_path: str,\n",
    "    target_audio_record_seconds: int = 3,\n",
    "    report: bool = True,\n",
    "    n_fft=2205,\n",
    "    mean_coefficient=0.8,\n",
    "    zone_size=5,\n",
    "):\n",
    "    fft_results, sr = get_spectogram(\n",
    "        target_audio_path, record_length=target_audio_record_seconds, n_fft=n_fft\n",
    "    )\n",
    "    constellation_map = create_constellation_map(\n",
    "        fft_results, mean_coefficient=mean_coefficient, hop_length=n_fft // 4\n",
    "    )\n",
    "    song_id = os.path.splitext(os.path.basename(target_audio_path))[0]\n",
    "    addresses_couples = create_address_value_couples(\n",
    "        constellation_map, song_id, zone_size=zone_size\n",
    "    )\n",
    "    # select the first 3 columns as the addresses\n",
    "    addresses = addresses_couples[:, :3]\n",
    "    results = search_address(db, addresses)\n",
    "    processed_results = process_matches(results)\n",
    "    if report:\n",
    "        print_results(processed_results, song_id=float(song_id))\n",
    "\n",
    "    if len(processed_results) == 0:\n",
    "        return constellation_map, results, False, False\n",
    "    found = processed_results[0][0] == float(song_id)\n",
    "\n",
    "    found_in_first_three = float(song_id) in np.array(processed_results[:3])[:, 0]\n",
    "\n",
    "    return constellation_map, results, found, found_in_first_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHUNKING FOR OPTIMIZATION\n",
    "\n",
    "\n",
    "def chunkify(target_array):\n",
    "    chunked_array = []\n",
    "\n",
    "    for band in LOGARITHMIC_BANDS:\n",
    "        band_array = target_array[\n",
    "            (target_array[:, 0] >= band[0]) & (target_array[:, 0] < band[1])\n",
    "        ]\n",
    "        chunked_array.append(band_array)\n",
    "    return chunked_array\n",
    "\n",
    "\n",
    "def search_chunked_address(db: np.array, _query: np.array):\n",
    "    results = []\n",
    "\n",
    "    for i, query in enumerate(_query):\n",
    "        matched_indicies = []\n",
    "\n",
    "        unique_query, counts = np.unique(query, axis=0, return_counts=True)\n",
    "\n",
    "        count = 1\n",
    "        # select the rows that have count == count\n",
    "        selected_query = unique_query[counts == count]\n",
    "        # np.sum(element == x) > 0\n",
    "        while len(selected_query) != 0:\n",
    "            matches = np.isin(db[i][:, :3], selected_query).all(axis=1)\n",
    "            matched_indicies.append(np.where(matches)[0])\n",
    "\n",
    "            count += 1\n",
    "            selected_query = unique_query[counts == count]\n",
    "\n",
    "        if len(matched_indicies) == 0:\n",
    "            continue\n",
    "        matched_indices = np.concatenate(matched_indicies)\n",
    "        results.append(db[i][matched_indices])\n",
    "\n",
    "    return np.concatenate(results)\n",
    "\n",
    "\n",
    "def chunked_search_song(\n",
    "    db: np.array,\n",
    "    target_audio_path: str,\n",
    "    target_audio_record_seconds: int = 3,\n",
    "    report: bool = True,\n",
    "    n_fft=2205,\n",
    "    mean_coefficient=0.8,\n",
    "    zone_size=5,\n",
    "):\n",
    "    fft_results, sr = get_spectogram(\n",
    "        target_audio_path, record_length=target_audio_record_seconds, n_fft=n_fft\n",
    "    )\n",
    "    constellation_map = create_constellation_map(\n",
    "        fft_results, mean_coefficient=mean_coefficient, hop_length=n_fft // 4\n",
    "    )\n",
    "    song_id = os.path.splitext(os.path.basename(target_audio_path))[0]\n",
    "    addresses_couples = create_address_value_couples(\n",
    "        constellation_map, song_id, zone_size=zone_size\n",
    "    )\n",
    "    addresses_couples = addresses_couples[:, :3]\n",
    "    addresses = chunkify(addresses_couples)\n",
    "    results = search_chunked_address(db, addresses)\n",
    "    processed_results = process_matches(results)\n",
    "    if report:\n",
    "        print_results(processed_results, song_id=float(song_id))\n",
    "\n",
    "    if len(processed_results) == 0:\n",
    "        return constellation_map, results, False, False\n",
    "\n",
    "    found = processed_results[0][0] == float(song_id)\n",
    "\n",
    "    found_in_first_three = float(song_id) in np.array(processed_results[:3])[:, 0]\n",
    "\n",
    "    return constellation_map, results, found, found_in_first_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUATION FUNCTIONS ###\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    number_of_audios, n_fft, mean_coefficient, zone_size, recording_length\n",
    "):\n",
    "    # Load the audios\n",
    "    audios = load_audios(\"data/fma_small/\", num_audios=number_of_audios)\n",
    "\n",
    "    # Save the spectograms if not exists\n",
    "    if not os.path.exists(f\"spectograms/{n_fft}_{len(audios)}.npy\"):\n",
    "        save_spectograms(audios, \"cache/spectograms/\", n_fft, recording_length)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Save the constellation maps if not exists\n",
    "    if not os.path.exists(f\"constellation_maps/{len(audios)}_{mean_coefficient}.npy\"):\n",
    "        save_constellation_maps(\n",
    "            f\"cache/spectograms/{n_fft}_{number_of_audios}.npy\",\n",
    "            \"cache/constellation_maps/\",\n",
    "            mean_coefficient=mean_coefficient,\n",
    "            hop_length=n_fft // 4,\n",
    "        )\n",
    "\n",
    "    # Create the address couples\n",
    "    addresses_couples = create_address_couples(\n",
    "        f\"cache/constellation_maps/{number_of_audios}_{mean_coefficient}.npy\"\n",
    "    )\n",
    "\n",
    "    # Search all the audios in the database one by one\n",
    "    found = 0\n",
    "    found_in_first_three = 0\n",
    "\n",
    "    for song_id, audio_path in audios.items():\n",
    "        _, _, _found, _found_in_first_three = search_song(\n",
    "            addresses_couples,\n",
    "            audio_path,\n",
    "            target_audio_record_seconds=recording_length,\n",
    "            report=False,\n",
    "            n_fft=n_fft,\n",
    "            mean_coefficient=mean_coefficient,\n",
    "            zone_size=zone_size,\n",
    "        )\n",
    "        if _found:\n",
    "            found += 1\n",
    "        if _found_in_first_three:\n",
    "            found_in_first_three += 1\n",
    "\n",
    "    # Append configurations and results to the csv file\n",
    "\n",
    "    found = found / number_of_audios * 100\n",
    "    found_in_first_three = found_in_first_three / number_of_audios * 100\n",
    "\n",
    "    columns = [\n",
    "        \"Number of Audios\",\n",
    "        \"n_fft\",\n",
    "        \"Mean Coefficient\",\n",
    "        \"Zone Size\",\n",
    "        \"Recording Length\",\n",
    "        \"Found\",\n",
    "        \"Found in First Three\",\n",
    "    ]\n",
    "\n",
    "    data = [\n",
    "        [\n",
    "            number_of_audios,\n",
    "            n_fft,\n",
    "            mean_coefficient,\n",
    "            zone_size,\n",
    "            recording_length,\n",
    "            found,\n",
    "            found_in_first_three,\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    reports = pd.read_csv(\"experiment_results.csv\")\n",
    "    reports = pd.concat([reports, df], ignore_index=True)\n",
    "    reports.to_csv(\"experiment_results.csv\", index=False)\n",
    "\n",
    "    print(f\"Found: {found}%\")\n",
    "    print(f\"Found in first three: {found_in_first_three}%\")\n",
    "\n",
    "    return found, found_in_first_three\n",
    "\n",
    "\n",
    "def grid_search():\n",
    "    candidate_audio_numbers = [10, 50, 100]\n",
    "    candidate_n_fft = [2205, 2048]\n",
    "    candidate_mean_coefficient = [0.8, 0.9, 1]\n",
    "    candidate_zone_size = [5, 10, 20]\n",
    "    candidate_recording_length = [5, 10, 20]\n",
    "    # Grid search\n",
    "\n",
    "    searched_configs = pd.read_csv(\"experiment_results.csv\")\n",
    "\n",
    "    for number_of_audios in candidate_audio_numbers:\n",
    "        for n_fft in candidate_n_fft:\n",
    "            for mean_coefficient in candidate_mean_coefficient:\n",
    "                for zone_size in candidate_zone_size:\n",
    "                    for recording_length in candidate_recording_length:\n",
    "                        config_row = {\n",
    "                            \"Number of Audios\": [number_of_audios],\n",
    "                            \"n_fft\": [n_fft],\n",
    "                            \"Mean Coefficient\": [mean_coefficient],\n",
    "                            \"Zone Size\": [zone_size],\n",
    "                            \"Recording Length\": [recording_length],\n",
    "                        }\n",
    "\n",
    "                        if (\n",
    "                            not searched_configs.iloc[:, :5]\n",
    "                            .isin(config_row)\n",
    "                            .all(axis=1)\n",
    "                            .any()\n",
    "                        ):\n",
    "                            run_experiment(\n",
    "                                number_of_audios,\n",
    "                                n_fft,\n",
    "                                mean_coefficient,\n",
    "                                zone_size,\n",
    "                                recording_length,\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\"Skipped\")\n",
    "                            print(config_row)\n",
    "                            print(\"-\" * 20)\n",
    "                            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_AUDIOS = 100\n",
    "MEAN_COEFFICIENT = 0.8\n",
    "N_FFT = 2205\n",
    "ZONE_SIZE = 5\n",
    "RECORDING_LENGTH = 5\n",
    "\n",
    "audios = load_audios(\"data/fma_small/\", num_audios=NUMBER_OF_AUDIOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = load_audios(\"data/fma_small/\", num_audios=NUMBER_OF_AUDIOS)\n",
    "\n",
    "# Save the spectograms if not exists\n",
    "if not os.path.exists(f\"spectograms/{N_FFT}_{len(audios)}.npy\"):\n",
    "    save_spectograms(audios, \"cache/spectograms/\", N_FFT, RECORDING_LENGTH)\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "# Save the constellation maps if not exists\n",
    "if not os.path.exists(f\"constellation_maps/{len(audios)}_{MEAN_COEFFICIENT}.npy\"):\n",
    "    save_constellation_maps(\n",
    "        f\"cache/spectograms/{N_FFT}_{NUMBER_OF_AUDIOS}.npy\",\n",
    "        \"cache/constellation_maps/\",\n",
    "        mean_coefficient=MEAN_COEFFICIENT,\n",
    "        hop_length=N_FFT // 4,\n",
    "    )\n",
    "\n",
    "# Create the address couples\n",
    "addresses_couples = create_address_couples(\n",
    "    f\"cache/constellation_maps/{NUMBER_OF_AUDIOS}_{MEAN_COEFFICIENT}.npy\"\n",
    ")\n",
    "# addresses_couples = chunkify(addresses_couples)\n",
    "\n",
    "# Search all the audios in the database one by one\n",
    "found = 0\n",
    "found_in_first_three = 0\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "\n",
    "for song_id, audio_path in audios.items():\n",
    "    print(f\"Searching {song_id}\")\n",
    "    t1 = time.time()\n",
    "    _, _, _found, _found_in_first_three = search_song(\n",
    "        addresses_couples,\n",
    "        audio_path,\n",
    "        target_audio_record_seconds=RECORDING_LENGTH,\n",
    "        n_fft=N_FFT,\n",
    "        mean_coefficient=MEAN_COEFFICIENT,\n",
    "        zone_size=ZONE_SIZE,\n",
    "        report=False,\n",
    "    )\n",
    "    total_time += time.time() - t1\n",
    "    if _found:\n",
    "        found += 1\n",
    "    if _found_in_first_three:\n",
    "        found_in_first_three += 1\n",
    "\n",
    "# not chunked db average search time = 0.2715\n",
    "# chunked db average search time = 0.2391\n",
    "\n",
    "print(\n",
    "    f\"Accuracy(definite): {found / len(audios) * 100}%, Accuracy(relative): {found_in_first_three / len(audios) * 100}%, Average Search Time: {total_time / len(audios)}s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concrete.fhe as fhe\n",
    "import numpy as np\n",
    "\n",
    "@fhe.circuit(\n",
    "    {\"db\": \"encrypted\", \"f1\": \"encrypted\", \"f2\": \"encrypted\", \"time\": \"encrypted\"}\n",
    ")\n",
    "def func(\n",
    "    db: fhe.tensor[fhe.uint16, 10, 1],\n",
    "    f1: fhe.uint16,\n",
    "    f2: fhe.uint16,\n",
    "    time: fhe.uint16\n",
    "):\n",
    "    matches = fhe.zero()\n",
    "\n",
    "    # address = fhe.array([f1, f2, time])\n",
    "    matches += db[0] == f1\n",
    "\n",
    "    return matches\n",
    "\n",
    "print(func.simulate([[1] for i in range(10)], 1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concrete.fhe as fhe\n",
    "import numpy as np\n",
    "\n",
    "@fhe.circuit({\"a\": \"encrypted\", \"b\": \"encrypted\"})\n",
    "def func(\n",
    "    a: fhe.uint16,\n",
    "    b: fhe.uint16\n",
    "):\n",
    "    return a + b\n",
    "\n",
    "func.simulate(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(func.simulate([[1,2,3] for i in range(10)], 1,2,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(func.encrypt_run_decrypt([[1,2,3] for i in range(10)], 1,2,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"experiment_results.csv\")\n",
    "df = df.sort_values(\n",
    "    by=[\"Found\", \"Found in First Three\", \"Number of Audios\"], ascending=False\n",
    ")[df[\"Recording Length\"] == 5]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]\n",
      " [11 12 13 14 15]]\n",
      " %0 = db                                    # EncryptedTensor<uint8, shape=(3, 5)>        ∈ [1, 15]\n",
      " %1 = query                                 # EncryptedTensor<uint3, shape=(2, 3)>        ∈ [1, 6]\n",
      " %2 = %0[:, :3]                             # EncryptedTensor<uint8, shape=(3, 3)>        ∈ [1, 13]\n",
      " %3 = %0[:, 3:]                             # EncryptedTensor<uint8, shape=(3, 2)>        ∈ [4, 15]\n",
      " %4 = zeros()                               # EncryptedTensor<uint8, shape=(3,)>          ∈ [0, 1]\n",
      " %5 = %2[0]                                 # EncryptedTensor<uint2, shape=(3,)>          ∈ [1, 3]\n",
      " %6 = %1[0]                                 # EncryptedTensor<uint2, shape=(3,)>          ∈ [1, 3]\n",
      " %7 = equal(%5, %6)                         # EncryptedTensor<uint1, shape=(3,)>          ∈ [1, 1]\n",
      " %8 = %7[0]                                 # EncryptedScalar<uint1>                      ∈ [1, 1]\n",
      " %9 = 0                                     # ClearScalar<uint1>                          ∈ [0, 0]\n",
      "%10 = add(%9, %8)                           # EncryptedScalar<uint1>                      ∈ [1, 1]\n",
      "%11 = %7[1]                                 # EncryptedScalar<uint1>                      ∈ [1, 1]\n",
      "%12 = add(%10, %11)                         # EncryptedScalar<uint2>                      ∈ [2, 2]\n",
      "%13 = %7[2]                                 # EncryptedScalar<uint1>                      ∈ [1, 1]\n",
      "%14 = add(%12, %13)                         # EncryptedScalar<uint8>                      ∈ [3, 3]\n",
      "%15 = %4[0]                                 # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%16 = 3                                     # ClearScalar<uint2>                          ∈ [3, 3]\n",
      "%17 = equal(%14, %16)                       # EncryptedScalar<uint1>                      ∈ [1, 1]\n",
      "%18 = add(%15, %17)                         # EncryptedScalar<uint1>                      ∈ [1, 1]\n",
      "%19 = (%4[0] = %18)                         # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 1]\n",
      "%20 = %2[0]                                 # EncryptedTensor<uint2, shape=(3,)>          ∈ [1, 3]\n",
      "%21 = %1[1]                                 # EncryptedTensor<uint3, shape=(3,)>          ∈ [4, 6]\n",
      "%22 = equal(%20, %21)                       # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 0]\n",
      "%23 = %22[0]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%24 = 0                                     # ClearScalar<uint1>                          ∈ [0, 0]\n",
      "%25 = add(%24, %23)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%26 = %22[1]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%27 = add(%25, %26)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%28 = %22[2]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%29 = add(%27, %28)                         # EncryptedScalar<uint8>                      ∈ [0, 0]\n",
      "%30 = %19[0]                                # EncryptedScalar<uint1>                      ∈ [1, 1]\n",
      "%31 = 3                                     # ClearScalar<uint2>                          ∈ [3, 3]\n",
      "%32 = equal(%29, %31)                       # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%33 = add(%30, %32)                         # EncryptedScalar<uint1>                      ∈ [1, 1]\n",
      "%34 = (%19[0] = %33)                        # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 1]\n",
      "%35 = %2[1]                                 # EncryptedTensor<uint4, shape=(3,)>          ∈ [6, 8]\n",
      "%36 = %1[0]                                 # EncryptedTensor<uint2, shape=(3,)>          ∈ [1, 3]\n",
      "%37 = equal(%35, %36)                       # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 0]\n",
      "%38 = %37[0]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%39 = 0                                     # ClearScalar<uint1>                          ∈ [0, 0]\n",
      "%40 = add(%39, %38)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%41 = %37[1]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%42 = add(%40, %41)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%43 = %37[2]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%44 = add(%42, %43)                         # EncryptedScalar<uint8>                      ∈ [0, 0]\n",
      "%45 = %34[1]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%46 = 3                                     # ClearScalar<uint2>                          ∈ [3, 3]\n",
      "%47 = equal(%44, %46)                       # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%48 = add(%45, %47)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%49 = (%34[1] = %48)                        # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 1]\n",
      "%50 = %2[1]                                 # EncryptedTensor<uint4, shape=(3,)>          ∈ [6, 8]\n",
      "%51 = %1[1]                                 # EncryptedTensor<uint3, shape=(3,)>          ∈ [4, 6]\n",
      "%52 = equal(%50, %51)                       # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 0]\n",
      "%53 = %52[0]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%54 = 0                                     # ClearScalar<uint1>                          ∈ [0, 0]\n",
      "%55 = add(%54, %53)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%56 = %52[1]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%57 = add(%55, %56)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%58 = %52[2]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%59 = add(%57, %58)                         # EncryptedScalar<uint8>                      ∈ [0, 0]\n",
      "%60 = %49[1]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%61 = 3                                     # ClearScalar<uint2>                          ∈ [3, 3]\n",
      "%62 = equal(%59, %61)                       # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%63 = add(%60, %62)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%64 = (%49[1] = %63)                        # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 1]\n",
      "%65 = %2[2]                                 # EncryptedTensor<uint4, shape=(3,)>          ∈ [11, 13]\n",
      "%66 = %1[0]                                 # EncryptedTensor<uint2, shape=(3,)>          ∈ [1, 3]\n",
      "%67 = equal(%65, %66)                       # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 0]\n",
      "%68 = %67[0]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%69 = 0                                     # ClearScalar<uint1>                          ∈ [0, 0]\n",
      "%70 = add(%69, %68)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%71 = %67[1]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%72 = add(%70, %71)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%73 = %67[2]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%74 = add(%72, %73)                         # EncryptedScalar<uint8>                      ∈ [0, 0]\n",
      "%75 = %64[2]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%76 = 3                                     # ClearScalar<uint2>                          ∈ [3, 3]\n",
      "%77 = equal(%74, %76)                       # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%78 = add(%75, %77)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%79 = (%64[2] = %78)                        # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 1]\n",
      "%80 = %2[2]                                 # EncryptedTensor<uint4, shape=(3,)>          ∈ [11, 13]\n",
      "%81 = %1[1]                                 # EncryptedTensor<uint3, shape=(3,)>          ∈ [4, 6]\n",
      "%82 = equal(%80, %81)                       # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 0]\n",
      "%83 = %82[0]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%84 = 0                                     # ClearScalar<uint1>                          ∈ [0, 0]\n",
      "%85 = add(%84, %83)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%86 = %82[1]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%87 = add(%85, %86)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%88 = %82[2]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%89 = add(%87, %88)                         # EncryptedScalar<uint8>                      ∈ [0, 0]\n",
      "%90 = %79[2]                                # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%91 = 3                                     # ClearScalar<uint2>                          ∈ [3, 3]\n",
      "%92 = equal(%89, %91)                       # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%93 = add(%90, %92)                         # EncryptedScalar<uint1>                      ∈ [0, 0]\n",
      "%94 = (%79[2] = %93)                        # EncryptedTensor<uint1, shape=(3,)>          ∈ [0, 1]\n",
      "%95 = reshape(%94, newshape=(3, 1))         # EncryptedTensor<uint1, shape=(3, 1)>        ∈ [0, 1]\n",
      "%96 = concatenate((%95, %3), axis=1)        # EncryptedTensor<uint4, shape=(3, 3)>        ∈ [0, 15]\n",
      "return %96\n"
     ]
    }
   ],
   "source": [
    "from concrete import fhe\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "NUM_ENTRIES = 3\n",
    "NUM_QUERIES = 2\n",
    "\n",
    "@fhe.compiler({\"db\": \"encrypted\", \"query\": \"encrypted\"})\n",
    "def num_matches(db, query):\n",
    "    assert db.ndim != 1\n",
    "    fhe.hint(db, bit_width=8)\n",
    "    fhe.hint(query, bit_width=8)\n",
    "\n",
    "    summation = fhe.hint(fhe.zero(), bit_width=8)\n",
    "    for i in range(NUM_ENTRIES):\n",
    "        sum_result = fhe.hint(sum(db[i] == query), bit_width=8)\n",
    "        summation += sum_result == 3\n",
    "\n",
    "    return summation\n",
    "\n",
    "\n",
    "@fhe.compiler({\"db\": \"encrypted\", \"query\": \"encrypted\"})\n",
    "def match_indices(db, query):\n",
    "    assert db.ndim != 1\n",
    "    fhe.hint(db, bit_width=8)\n",
    "    # fhe.hint(query, bit_width=8)\n",
    "\n",
    "    db_address = fhe.hint(db[:, :3], bit_width=8)\n",
    "    db_rest = fhe.hint(db[:, 3:], bit_width=8)\n",
    "\n",
    "    matches = fhe.hint(fhe.zeros(NUM_ENTRIES), bit_width=8)\n",
    "    for i in range(NUM_ENTRIES):\n",
    "        for j in range(NUM_QUERIES): \n",
    "            sum_result = fhe.hint(sum(db_address[i] == query[j]), bit_width=8)\n",
    "            matches[i] += sum_result == 3\n",
    "    \n",
    "\n",
    "    results = np.concatenate((matches.reshape(NUM_ENTRIES, 1), db_rest), axis=1)\n",
    "    return results\n",
    "\n",
    "@fhe.compiler({\"db\": \"encrypted\", \"query\": \"encrypted\"})\n",
    "def matching_numbers(db, query):\n",
    "    assert db.ndim != 1\n",
    "\n",
    "    matches = fhe.zeros(NUM_ENTRIES)\n",
    "    for i in range(NUM_ENTRIES):\n",
    "        matches[i] = sum(db[i] == query)\n",
    "\n",
    "    return matches\n",
    "\n",
    "\n",
    "\n",
    "db = np.linspace(1, NUM_ENTRIES * 5, num=NUM_ENTRIES*5, dtype=np.uint16).reshape(NUM_ENTRIES, 5)\n",
    "# query = np.array([1, 2, 3], dtype=np.uint16).reshape(1, 3)\n",
    "\n",
    "print(db)\n",
    "\n",
    "inputset= [(db, [[1,2,3], [4,5,6]])]\n",
    "\n",
    "# num_matches = num_matches.compile(inputset)\n",
    "match_indices = match_indices.compile(inputset)\n",
    "print(match_indices)\n",
    "# matching_numbers = matching_numbers.compile(inputset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 5]\n",
      " [1 7 5]\n",
      " [1 4 5]]\n"
     ]
    }
   ],
   "source": [
    "# print(circuit.encrypt_run_decrypt([[1,2,3], [1,2,3]], [1,2,3]))\n",
    "# print(num_matches.simulate([[1,2,3] for i in range(NUM_ENTRIES)], [1,2,3]))\n",
    "print(\n",
    "    match_indices.simulate(\n",
    "        [[1, 2, 3, 4, 5], [1, 2, 3, 7, 5], [1, 0, 3, 4, 5]], [[1, 2, 3], [1, 2, 3]]\n",
    "    )\n",
    ")\n",
    "# print(matching_numbers.simulate([[1,2,3] for i in range(NUM_ENTRIES)], [1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ShazamServer:\n",
    "    db: np.array\n",
    "\n",
    "    def __init__(self, db: np.array):\n",
    "        self.db = db\n",
    "        \n",
    "    def search(self, encrypted_address):\n",
    "        return match_indices.run(encrypted_address)\n",
    "\n",
    "class ShazamClient:\n",
    "    def process_recording(self, recording: np.array):\n",
    "        return [[1, 2, 3]]\n",
    "\n",
    "    def encrypt(self, db, address):\n",
    "        return match_indices.encrypt(db, address)\n",
    "\n",
    "    def decrypt(self, results):\n",
    "        return match_indices.decrypt(results)\n",
    "\n",
    "\n",
    "server = ShazamServer(db)\n",
    "client = ShazamClient()\n",
    "\n",
    "recording = None\n",
    "query = client.process_recording(recording)\n",
    "\n",
    "for address in query:\n",
    "    print(\"(client) Encrypting address...\")\n",
    "    encrypted_address = client.encrypt(server.db, address)\n",
    "    print(\"(server) Searching address...\")\n",
    "    results = server.search(encrypted_address)\n",
    "    print(\"(client) Decrypting results...\")\n",
    "    decrypted_results = client.decrypt(results)\n",
    "    print(\"(client) Processing results...\")\n",
    "    matched_indices = np.where(decrypted_results == 1)[0]\n",
    "    print(matched_indices)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
